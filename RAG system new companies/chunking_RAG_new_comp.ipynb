{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c851ee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (0.3.17)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain) (0.3.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain) (0.3.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-generativeai) (2.24.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-generativeai) (2.160.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\automac\\desktop\\aip\\finq&a\\myenvironment\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\AutomaC\\Desktop\\AIP\\FinQ&A\\myenvironment\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e061a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully embedded all 147 text chunks!\n",
      "\n",
      "🔹 Chunk 1: ID: AMD_Q4 2023.txt\n",
      "Table of ContentsPART IITEM 1. BUSINESS Cautionary Statement Regarding Forward-L...\n",
      "🟢 Embedding 1: [0.0069469972513616085, -0.012498626485466957, -0.03598563373088837, 0.0023446690756827593, 0.0678253099322319]...\n",
      "\n",
      "🔹 Chunk 2: ==================================================...\n",
      "🟢 Embedding 2: [0.022281521931290627, -0.002733333269134164, -0.07591065764427185, -0.007210069335997105, 0.047469064593315125]...\n",
      "\n",
      "🔹 Chunk 3: ID: AT&T_Q3 2024.txt\n",
      "TABLE OF CONTENTSSection 1.1 The Debt-Financed Distribution 2Section 1.2 INVIDI...\n",
      "🟢 Embedding 3: [-0.011203193105757236, 0.006782775279134512, -0.03247274085879326, -0.011494665406644344, 0.03130218759179115]...\n",
      "\n",
      "🔹 Chunk 4: ==================================================...\n",
      "🟢 Embedding 4: [0.022281521931290627, -0.002733333269134164, -0.07591065764427185, -0.007210069335997105, 0.047469064593315125]...\n",
      "\n",
      "🔹 Chunk 5: ID: AT&T_Q4 2023.txt\n",
      "TABLE OF CONTENTSPART IITEM 1. BUSINESSGENERALAT&T Inc. (“AT&T,” “we” or the “C...\n",
      "🟢 Embedding 5: [0.047201041132211685, -0.028912264853715897, -0.012682156637310982, 0.0031161410734057426, 0.07043658196926117]...\n",
      "157.20209789276123\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import time\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"GOOGLE_API_KEY\"\n",
    "\n",
    "file_path = r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\combined_document.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    combined_text = f.read()\n",
    "\n",
    "text_chunks = combined_text.split(\"\\n\\n\")\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "embeddings = embedding_model.embed_documents(text_chunks)\n",
    "\n",
    "# ✅ Check for mismatched counts\n",
    "if len(text_chunks) == len(embeddings):\n",
    "    print(f\"✅ Successfully embedded all {len(text_chunks)} text chunks!\")\n",
    "else:\n",
    "    print(f\"⚠️ Mismatch detected! Expected {len(text_chunks)} embeddings, but got {len(embeddings)}.\")\n",
    "\n",
    "# Print first 5 embeddings for verification\n",
    "for i, (text, embed) in enumerate(zip(text_chunks[:5], embeddings[:5])):\n",
    "    print(f\"\\n🔹 Chunk {i+1}: {text[:100]}...\")  # Print first 100 characters\n",
    "    print(f\"🟢 Embedding {i+1}: {embed[:5]}...\")  # Print first 5 embedding values\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29e08a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully chunked document into 20978 chunks! Saved to C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\final_chunked_document.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_by_headings(text):\n",
    "    \"\"\"Chunk document by headings (H1, H2, etc.).\"\"\"\n",
    "    chunks = re.split(r\"\\n\\s*(?=[A-Z][A-Za-z ]{3,}\\n)\", text)  # Split at uppercase headings\n",
    "    return [chunk.strip() for chunk in chunks if chunk.strip()]\n",
    "\n",
    "def recursive_chunking(chunks, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Apply recursive chunking after heading-based split.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    refined_chunks = []\n",
    "    for chunk in chunks:\n",
    "        refined_chunks.extend(text_splitter.split_text(chunk))\n",
    "    return refined_chunks\n",
    "\n",
    "# Load the document\n",
    "file_path = r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\combined_document.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    document_text = f.read()\n",
    "\n",
    "# Step 1: Split by headings\n",
    "heading_chunks = split_by_headings(document_text)\n",
    "\n",
    "# Step 2: Apply Recursive Chunking\n",
    "final_chunks = recursive_chunking(heading_chunks)\n",
    "\n",
    "# Save output\n",
    "output_path = r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\final_chunked_document.json\"\n",
    "import json\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_chunks, f, indent=4)\n",
    "\n",
    "print(f\"✅ Successfully chunked document into {len(final_chunks)} chunks! Saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af04eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunking completed. Total Chunks: 20978\n",
      "✅ Embeddings generated for 20978 chunks in 525.94 seconds.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error in __cdecl faiss::FileIOWriter::FileIOWriter(const char *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\io.cpp:102: Error: 'f' failed: could not open C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_index for writing: Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29660\\2411018511.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexFlatL2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m# Save FAISS index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_chunks.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\faiss\\swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m  10830\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10831\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Error in __cdecl faiss::FileIOWriter::FileIOWriter(const char *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\io.cpp:102: Error: 'f' failed: could not open C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_index for writing: Permission denied"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "import ollama\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# ✅ Set API Key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"GOOGLE_API_KEY\"\n",
    "\n",
    "# ✅ Load Document\n",
    "file_path = r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\combined_document.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    document_text = f.read()\n",
    "\n",
    "# ✅ 1️⃣ STEP 1: Chunking (Heading-Based + Recursive Character-Based)\n",
    "def split_by_headings(text):\n",
    "    \"\"\"Split document by headings (H1, H2, etc.).\"\"\"\n",
    "    chunks = re.split(r\"\\n\\s*(?=[A-Z][A-Za-z ]{3,}\\n)\", text)  # Split at uppercase headings\n",
    "    return [chunk.strip() for chunk in chunks if chunk.strip()]\n",
    "\n",
    "def recursive_chunking(chunks, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Apply recursive chunking after heading-based split.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    refined_chunks = []\n",
    "    for chunk in chunks:\n",
    "        refined_chunks.extend(text_splitter.split_text(chunk))\n",
    "    return refined_chunks\n",
    "\n",
    "# Apply chunking\n",
    "heading_chunks = split_by_headings(document_text)\n",
    "final_chunks = recursive_chunking(heading_chunks)\n",
    "\n",
    "print(f\"✅ Chunking completed. Total Chunks: {len(final_chunks)}\")\n",
    "\n",
    "# ✅ 2️⃣ STEP 2: Generate Embeddings Using Google AI\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "start_time = time.time()\n",
    "embeddings = embedding_model.embed_documents(final_chunks)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"✅ Embeddings generated for {len(final_chunks)} chunks in {round(end_time - start_time, 2)} seconds.\")\n",
    "\n",
    "# ✅ 3️⃣ STEP 3: Store Embeddings in FAISS\n",
    "embeddings_array = np.array(embeddings).astype(\"float32\")\n",
    "dimension = embeddings_array.shape[1]  # Get embedding dimensions\n",
    "\n",
    "# Initialize FAISS Index\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings_array)\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_index\")\n",
    "with open(r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_chunks, f, indent=4)\n",
    "\n",
    "print(f\"✅ FAISS index stored with {index.ntotal} embeddings!\")\n",
    "\n",
    "# ✅ 4️⃣ STEP 4: Load FAISS & Ollama for Querying\n",
    "index = faiss.read_index(r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_index\")\n",
    "with open(r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stored_chunks = json.load(f)\n",
    "\n",
    "# Convert stored chunks into LangChain Document objects\n",
    "docs = [Document(page_content=chunk) for chunk in stored_chunks]\n",
    "\n",
    "# Convert FAISS into a LangChain retriever\n",
    "faiss_vector_db = FAISS(embedding_function=embedding_model.embed_query, index=index, texts=[doc.page_content for doc in docs])\n",
    "retriever = faiss_vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67c6984a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m faiss_vector_db\u001b[38;5;241m.\u001b[39msave_local(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAutomaC\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAIP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRAG system new companies\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mextracted_sec_text\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfaiss_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# ✅ Load the FAISS Index for Retrieval\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m faiss_vector_db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_local\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mAutomaC\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mAIP\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mRAG system new companies\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mextracted_sec_text\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mfaiss_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ✅ Create the retriever\u001b[39;00m\n\u001b[0;32m     22\u001b[0m retriever \u001b[38;5;241m=\u001b[39m faiss_vector_db\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "File \u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1190\u001b[0m, in \u001b[0;36mFAISS.load_local\u001b[1;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load FAISS index, docstore, and index_to_docstore_id from disk.\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m \n\u001b[0;32m   1178\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;124;03m        arbitrary code on your machine.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_deserialization:\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe de-serialization relies loading a pickle file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickle files can be modified to deliver a malicious payload that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults in execution of arbitrary code on your machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will need to set `allow_dangerous_deserialization` to `True` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable deserialization. If you do this, make sure that you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust the source of the data. For example, if you are loading a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile that you created, and know that no one else has modified the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, then this is safe to do. Do not set this to `True` if you are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading a file from an untrusted source (e.g., some random site on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1200\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe internet.).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1201\u001b[0m     )\n\u001b[0;32m   1202\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(folder_path)\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;66;03m# load index separately since it is not picklable\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.)."
     ]
    }
   ],
   "source": [
    "# ✅ 4️⃣ STEP 4: Load FAISS & Ollama for Querying\n",
    "index = faiss.read_index(r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\faiss_index\")\n",
    "with open(r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stored_chunks = json.load(f)\n",
    "\n",
    "# Convert stored chunks into LangChain Document objects\n",
    "docs = [Document(page_content=chunk) for chunk in stored_chunks]\n",
    "\n",
    "# ✅ Create FAISS vector store from texts\n",
    "faiss_vector_db = FAISS.from_texts(\n",
    "    [doc.page_content for doc in docs],  # Text content for FAISS storage\n",
    "    embedding_model,  # Embedding function\n",
    ")\n",
    "\n",
    "# ✅ Save FAISS Index (Persistence)\n",
    "faiss_vector_db.save_local(r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_index\")\n",
    "\n",
    "# ✅ Load the FAISS Index for Retrieval\n",
    "faiss_vector_db = FAISS.load_local(r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_index\", embedding_model)\n",
    "\n",
    "# ✅ Create the retriever\n",
    "retriever = faiss_vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "492d079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Load the FAISS Index for Retrieval\n",
    "faiss_vector_db = FAISS.load_local(r\"C:\\Users\\AutomaC\\Desktop\\AIP\\RAG system new companies\\extracted_sec_text\\faiss_index\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# ✅ Create the retriever\n",
    "retriever = faiss_vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9010b506",
   "metadata": {},
   "source": [
    " retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cf69d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000026ED6CD2510>, search_kwargs={})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "add6cc1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ✅ Example Query\u001b[39;00m\n\u001b[0;32m     27\u001b[0m user_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the primary segments that AMD operates in?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 28\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_groq\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_question\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🔹 Response from Groq:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response)\n",
      "Cell \u001b[1;32mIn[14], line 22\u001b[0m, in \u001b[0;36mquery_groq\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m     19\u001b[0m retrieved_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m relevant_docs])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ✅ Construct query using LangChain LLM (No API URL required)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBased on the following retrieved information, answer the question:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mretrieved_text\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mQuestion: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquestion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    283\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 690\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m         )\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\langchain_groq\\chat_models.py:480\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    476\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    479\u001b[0m }\n\u001b[1;32m--> 480\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:322\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    199\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\groq\\_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1265\u001b[0m     )\n\u001b[1;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\groq\\_base_client.py:958\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    956\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\AIP\\FinQ&A\\myenvironment\\Lib\\site-packages\\groq\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mInternalServerError\u001b[0m: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_core.documents import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_groq import ChatGroq  # ✅ Use ChatGroq for API integration\n",
    "\n",
    "# ✅ Set API Key for Groq\n",
    "os.environ[\"GROQ_API_KEY\"] = \"GROQ_API_KEY\"\n",
    "\n",
    "# ✅ Load Groq Model via LangChain\n",
    "llm = ChatGroq(model_name=\"gemma2-9b-it\")  \n",
    "\n",
    "# ✅ Function to Query FAISS and Generate Response using Groq\n",
    "def query_groq(question):\n",
    "    # Retrieve relevant chunks from FAISS\n",
    "    relevant_docs = retriever.get_relevant_documents(question)\n",
    "    retrieved_text = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    # ✅ Construct query using LangChain LLM (No API URL required)\n",
    "    response = llm.invoke(f\"Based on the following retrieved information, answer the question:\\n\\n{retrieved_text}\\n\\nQuestion: {question}\")\n",
    "\n",
    "    return response\n",
    "\n",
    "# ✅ Example Query\n",
    "user_question = \"What are the primary segments that AMD operates in?\"\n",
    "response = query_groq(user_question)\n",
    "print(\"\\n🔹 Response from Groq:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8325415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Function to Query FAISS and Use Ollama for Response\n",
    "def query_ollama(question, model=\"qwen:1.8b\"):\n",
    "    \"\"\"\n",
    "    Retrieves relevant chunks from FAISS and queries Ollama LLM.\n",
    "    \n",
    "    Args:\n",
    "    - question (str): User question.\n",
    "    - model (str): LLM model to use (e.g., \"mistral\", \"gemma\", \"llama3\").\n",
    "\n",
    "    Returns:\n",
    "    - str: LLM-generated answer.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # ✅ Query Ollama LLM\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an financial AI assistant that provides concise answers based on retrieved documents.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Based on the following retrieved information, answer the question:\\n\\n{retrieved_text}\\n\\nQuestion: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58220b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Question you needs to ask?What is AMD's primary business focus?\n",
      "\n",
      "🔹 Response from Ollama:\n",
      " AMD's primary business focus is serving the global consumer market for custom-designed high-performance computing (HPC) solutions and products. The company has a diverse portfolio of HPC products and services, including Ryzen processors, EPYC servers, GPUs, FPGAs, smartNICs, AI accelerators, and Adaptive SoC products.\n",
      "\n",
      "AMD's primary business focus is centered around providing customized HPC solutions that meet the specific needs and requirements of its clients. The company has a proven track record of delivering high-quality custom-designed HPC solutions to its clients, thereby contributing significantly to their operations and increasing their overall competitiveness in the global consumer market for custom-designed HPC solutions\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"What Question you needs to ask?\")\n",
    "response = query_ollama(user_question, model=\"qwen:1.8b\")  # Change model if needed\n",
    "print(\"\\n🔹 Response from Ollama:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c72e16aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Question you needs to ask?What are AMD’s four primary business segments?\n",
      "\n",
      "🔹 Response from Ollama:\n",
      " AMD's four primary business segments are as follows:\n",
      "\n",
      "1. Data Center Graphics Segment:\n",
      "   - This segment focuses on providing high-performance graphics solutions for data center environments, such as servers, routers, switches, and storage systems.\n",
      "   - The products offered in this segment include AMD Radeon Pro graphics chips, AMD EPYC processors, AMD Xe server blades, and other related graphics cards and systems.\n",
      "\n",
      "2. Server Micrographics Segment:\n",
      "   - This segment focuses on providing a wide range of high-performance micrograph solutions for both server and embedded applications, such as notebooks, laptops, desktop computers, embedded devices, IoT devices, smart edge devices, drones, autonomous vehicles, and other related micrograph systems and products.\n",
      "   \n",
      "3. Test and Measurement Graphics Segment:\n",
      "   - This segment focuses on providing a wide range of high-performance test and measurement graphics solutions for both enterprise-level testing environments and consumer-level testing platforms, such as desktops, laptops, smartphones, tablets, smart TVs, smart home appliances, and other related testing graphics systems and products.\n",
      "   \n",
      "4. Industrial Graphics Segment:\n",
      "   - This segment focuses on providing a wide range of high-performance industrial graphics solutions for both manufacturing plants and process control centers, such as machinery components, equipment automation, intelligent manufacturing systems, smart factories, smart logistics, advanced manufacturing technology, automation engineering, and other related industrial graphics systems and products.\n",
      "   \n",
      "AMD's four primary business segments are essential for the company to efficiently market its diverse range of products and services across different vertical markets.\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"What Question you needs to ask?\")\n",
    "response = query_ollama(user_question, model=\"qwen:1.8b\")  # Change model if needed\n",
    "print(\"\\n🔹 Response from Ollama:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bcb1b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Question you needs to ask?What products does AMD offer for the data center market?\n",
      "\n",
      "🔹 Response from Ollama:\n",
      " AMD offers a wide range of products for the data center market. Some of the key products offered by AMD include:\n",
      "\n",
      "1. CPUs (Central Processing Units): \n",
      "   AMD offers a diverse range of CPUs for the data center market. Some of the key CPU models offered by AMD include:\n",
      "\n",
      "  * AMD EPYC™ processors:\n",
      "     AMD EPYC™ processors are designed to deliver high performance, energy efficiency, and scalability in the data center market. Some of the key features and capabilities of AMD EPYC™ processors include:\n",
      "\n",
      "  * High-performance CPU architecture: \n",
      "     AMD EPYC™ processors feature a high-performance CPU (CPU) architecture that enables efficient execution of operations and tasks across the data center market.\n",
      "\n",
      "  * Advanced energy efficiency design: \n",
      "     AMD EPYC™ processors are designed to deliver advanced energy efficiency in the data center market. Some of the key features and capabilities of AMD EPYC™ processors for energy efficiency include:\n",
      "\n",
      "  * High-performance CPU architecture with low power consumption: \n",
      "     AMD EPYC™ processors feature a high-performance CPU (CPU) architecture that includes advanced memory management, such as multiple levels of cache and shared memory between different parts of the processor, which enables efficient execution of operations and tasks across the data center market, resulting in improved energy efficiency compared to traditional CPUs.\n",
      "\n",
      "  * Advanced AI acceleration design: \n",
      "     AMD EPYC™ processors are designed to deliver advanced AI acceleration in the data center market. Some of the key features and capabilities of AMD EPYC™ processors for AI acceleration include:\n",
      "\n",
      "  * High-performance CPU architecture with AI acceleration support: \n",
      "     AMD EPYC™ processors feature a high-performance CPU (CPU) architecture that includes advanced AI acceleration support, such as the use of multiple generations of GPUs with tailored AI acceleration capabilities to handle the increasing demands on AI acceleration in the data center market. This enables efficient execution of operations and tasks across the data center market, resulting in improved energy efficiency compared to traditional CPUs.\n",
      "\n",
      "  * Advanced networking software stack: \n",
      "     AMD EPYC™ processors are designed to deliver advanced networking software stack that includes a high-performance CPU (CPU) architecture with AI acceleration support, along with comprehensive networking software stack that includes advanced IP addressing and routing capabilities, as well as advanced network security features including firewalls, intrusion detection systems (IDS), and security information and event management (SIEM) systems. This enables efficient execution of operations and tasks across the data center market, resulting in improved energy efficiency compared to traditional CPUs.\n",
      "\n",
      "  * Advanced AI acceleration support: \n",
      "     AMD EPYC™ processors are designed to deliver advanced AI acceleration support that includes a high-performance CPU (CPU) architecture with AI acceleration support, along with comprehensive AI acceleration support features including machine learning algorithms, deep neural networks (DNNs), and computer vision algorithms, as well as advanced AI acceleration support capabilities such as automatic learning for efficient execution of complex AI tasks, and adaptive training for seamless adoption of advanced AI techniques across different workloads and applications. This enables efficient execution of operations and tasks across the data center market, resulting in improved energy efficiency compared to traditional CPUs.\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"What Question you needs to ask?\")\n",
    "response = query_ollama(user_question, model=\"qwen:1.8b\")  # Change model if needed\n",
    "print(\"\\n🔹 Response from Ollama:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e05d7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Question you needs to ask?What offerings does Google Cloud provide?\n",
      "\n",
      "🔹 Response from Ollama:\n",
      " Google Cloud provides a wide range of cloud-based services and offerings across various categories such:\n",
      "\n",
      "  1. **Infrastructure-as-a-Service (IaaS)**:** This category offers on-demand computing resources, including virtual machines, storage, and network connectivity services, enabling customers to rent or purchase computing resources as needed without the need for upfront capital investments.\n",
      "    \n",
      "  2. **Platform-as-a--Service (PaaS)**:** This category offers software platforms that allow developers to build, deploy, and manage applications and other software services on a serverless architecture, enabling customers to focus on application development and deployment rather than worrying about infrastructure management and costs.\n",
      "    \n",
      "  3. **Cloud Functions**: This category offers compute services in the form of virtual machines and other computing resources that can be invoked by APIs or other triggers to perform arbitrary actions or processes, enabling customers to deploy and use computationally intensive functions and processes as needed without the need for upfront capital investments.\n",
      "    \n",
      "  4. **BigQuery**: This category offers data warehousing and analysis services in the form of big data analytics solutions that enable customers to store, process, analyze, and visualize large volumes of structured, semi-structured, and unstructured data from various sources, enabling them to extract insights and knowledge from the data, enabling customers to make better-informed decisions, streamline their operations, increase efficiency, reduce costs, optimize resource allocation, enhance operational agility, and enable new business models\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"What Question you needs to ask?\")\n",
    "response = query_ollama(user_question, model=\"qwen:1.8b\")  # Change model if needed\n",
    "print(\"\\n🔹 Response from Ollama:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f9100d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Question you needs to ask?How does Google protect user data and privacy?\n",
      "\n",
      "🔹 Response from Ollama:\n",
      " Google protects user data and privacy through a combination of technical measures and legal compliance.\n",
      "1. Technical Measures:\n",
      "   - Data Encryption: Google uses encryption algorithms like AES (Advanced Encryption Standard) to protect user data in transit. This ensures that even if an attacker intercepts the encrypted data during transmission, they will not be able to read or access the original data without first decrypting it using the same encryption algorithm used to encrypt the data.\n",
      "   - Data Access Controls: Google has implemented strict data access controls (DACs)) to ensure that only authorized personnel have access to sensitive user data. This involves implementing role-based access control (RBAC) policies, which specify who can perform specific actions within a particular resource scope or permission level. This ensures that even if an attacker attempts to gain unauthorized access to sensitive user data by exploiting vulnerabilities in Google's security and privacy measures, they will not be able to access the sensitive user data without first being granted appropriate levels of authorization and access controls.\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"What Question you needs to ask?\")\n",
    "response = query_ollama(user_question, model=\"qwen:1.8b\")  # Change model if needed\n",
    "print(\"\\n🔹 Response from Ollama:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f44663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Question you needs to ask?What legal and regulatory risks does Google face?\n",
      "\n",
      "🔹 Response from Ollama:\n",
      " Google faces several legal and regulatory risks, which can have significant implications for the company's business operations, competitive position, financial health, and overall brand reputation.\n",
      "\n",
      "1. Regulatory Compliance Risks:\n",
      "\n",
      "a) Federal Trade Commission (FTC): The FTC is responsible for enforcing antitrust laws, including those related to Google's advertising practices. In 2018, the FTC launched an investigation into Google's advertising practices, including its use of ad blockers, and whether it was engaging in anti-competitive behavior. The FTC found that Google was using ad blockers to reduce the amount of money paid for search engine advertising, and that Google was also engaging in anti-competitive behavior by using its dominant position in the online advertising market to restrict access to its ad inventory, which could limit the number of ads displayed on Google's search engine results pages. The FTC further found that Google had been engaging in anti-competitive behavior by using its dominant position in the online advertising market to restrict access to its ad inventory, and that Google had also engaged in anti-competitive behavior by using its dominant position in the online advertising market to influence the content of search engine results pages, which could limit the number of ads displayed on Google's search engine results pages.\n",
      "\n",
      "b) European Commission (EC): The EC is responsible for enforcing EU law, including those related to competition and consumer protection. In 2018, the EC launched an investigation into Google's advertising practices, including its use of ad blockers, and whether it was engaging in anti-competitive behavior by using its dominant position in the online advertising market to restrict access to its ad inventory, and that Google had also engaged in anti-competitive behavior by using its dominant position in the online advertising market to influence the content of search engine results pages, which could limit the number of ads displayed on Google's search engine results pages.\n",
      "\n",
      "c) United States Federal Trade Commission (FTC): The FTC is responsible for enforcing antitrust laws, including those related to competition and consumer protection. In 2018, the FTC launched an investigation into Google's advertising practices, including its use of ad blockers, and whether it was engaging in anti-competitive behavior by using its dominant position in the online advertising market to restrict access to its ad inventory, and that Google had also engaged in anti-competitive behavior by using its dominant position in the online advertising market to influence the content of search engine results pages, which could limit the number of ads displayed on Google's search engine results pages\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"What Question you needs to ask?\")\n",
    "response = query_ollama(user_question, model=\"qwen:1.8b\")  # Change model if needed\n",
    "print(\"\\n🔹 Response from Ollama:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92bc51f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Question you needs to ask?How does Google’s advertising model work?\n",
      "\n",
      "🔹 Response from Ollama:\n",
      " Google's advertising model works through a combination of revenue models, targeting and optimization strategies, and content management systems.\n",
      "\n",
      "1. Revenue Models:\n",
      "    - AdWords revenue model: This model generates revenue when users click on ads displayed in the context of search queries.\n",
      "    - Google Display Network (GDN) revenue model: This model generates revenue when users view ads displayed on third-party websites participating in the GDN network.\n",
      "    - YouTube revenue model: This model generates revenue when a user interacts with a YouTube video, such as watching or sharing a video. The revenue generated from these interactions is recognized in the relevant financial statements.\n",
      "\n",
      "2. Targeting and Optimization Strategies:\n",
      "    - Keyword targeting: Google's advertising platform allows advertisers to target specific keywords that are likely to appear in search queries.\n",
      "    - Geographic targeting: Google's advertising platform also allows advertisers to target specific geographic locations, such as states or countries.\n",
      "    - Device targeting: Google's advertising platform allows advertisers to target specific devices, such as smartphones or tablets. For example, an advertiser may choose to target mobile users who are searching for a particular app or service.\n",
      "\n",
      "3. Content Management Systems:\n",
      "    - YouTube content management system: This system manages the content and metadata associated with YouTube videos, including video title, description, tags, upload date, expiration date, views, subscribers, and monetization options.\n",
      "    - Google Ads content management system: This system manages the content and metadata associated with Google Ads campaigns, including campaign name, description, keywords, ad group manager account, ad group code, budget, conversions, cost per conversion, daily average clicks, daily average impressions, engagement rate, hits, impressions, keyword density, landing page URLs, link building activities, and monetization options.\n",
      "Note: These are generalizations of Google's advertising model and the specific requirements of each revenue model.\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"What Question you needs to ask?\")\n",
    "response = query_ollama(user_question, model=\"qwen:1.8b\")  # Change model if needed\n",
    "print(\"\\n🔹 Response from Ollama:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Function to Query FAISS and Use Ollama for Response\n",
    "def query_ollama(question, model=\"qwen:1.8b\"):\n",
    "    \"\"\"\n",
    "    Retrieves relevant chunks from FAISS and queries Ollama LLM.\n",
    "    \n",
    "    Args:\n",
    "    - question (str): User question.\n",
    "    - model (str): LLM model to use (e.g., \"mistral\", \"gemma\", \"llama3\").\n",
    "\n",
    "    Returns:\n",
    "    - str: LLM-generated answer.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # ✅ Query Ollama LLM\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an financial AI assistant that provides concise answers based on retrieved documents.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Based on the following retrieved information, answer the question:\\n\\n{retrieved_text}\\n\\nQuestion: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8070de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# ✅ Set API Key for Groq\n",
    "GROQ_API_KEY = \"GROQ_API_KEY\"\n",
    "\n",
    "def query_llm_groq(question):\n",
    "    \"\"\"Queries Groq API (gemma2-9b-it model) and returns the response.\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve relevant chunks from FAISS\n",
    "        relevant_docs = retriever.get_relevant_documents(question)\n",
    "        retrieved_text = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "        \n",
    "        # ✅ Initialize Groq API client\n",
    "        client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "        # ✅ Construct API request\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            messages=\n",
    "                 [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"You are an financial AI assistant that provides concise answers based on retrieved documents. Based on the following retrieved information, answer the question:\\n\\n{retrieved_text}\\n\\nQuestion: {question}\"\n",
    "                  }],\n",
    "            temperature=0.3,\n",
    "            max_tokens=512,\n",
    "            top_p=1,\n",
    "            stream=False,\n",
    "        )\n",
    "\n",
    "            \n",
    "        # ✅ Extract and return response content\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"❌ Groq API Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fce32977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Enter your financial question: How much worth is to invest in google?\n",
      "\n",
      "🔹 Response from Groq:\n",
      " The value of investing in Google (Alphabet Inc.) depends on various factors, including the investor's financial goals, risk tolerance, and market conditions. As of December 31, 2023, there were approximately 7,305 and 1,757 stockholders of record of Google's Class A and Class C stock, respectively. Google has never declared or paid any cash dividend on its common or capital stock. The company's primary use of capital is for headcount, particularly due to annual stock-based compensation awards that generally vest over four years. Cost of revenues is comprised of Traffic Acquisition Costs (TAC) and other costs of revenues, including compensation expenses related to data centers and other operations, content acquisition costs, depreciation expense, and inventory.\n",
      "\n",
      "Google is investing significantly in its Research and Development (R&D) efforts, including metaverse and wearables, which may not generate profits for several years. In 2024, the R&D segment reduced Google's overall operating profit by approximately $17.73 billion, and the company expects R&D operating losses to increase in 2025.\n",
      "\n",
      "It is recommended to consult a financial advisor or conduct thorough research before making investment decisions.\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"\\n💬 Enter your financial question: \")\n",
    "response = query_llm_groq(user_question)\n",
    "print(\"\\n🔹 Response from Groq:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75707a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnvironment",
   "language": "python",
   "name": "myenvironment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
